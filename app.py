import streamlit as st
import chromadb
from sentence_transformers import SentenceTransformer
import torch
import os

# --- è¨­å®š (å¿…é ˆèˆ‡ ingest_data.py ä¸­çš„è¨­å®šä¸€è‡´) ---
MODEL_NAME = "maidalun1020/bce-embedding-base_v1"
DB_STORAGE_PATH = os.path.join(os.path.dirname(__file__), "vector_storage")
COLLECTION_NAME = "tsmc_news"

# --- Streamlit æ‡‰ç”¨ç¨‹å¼ ---

st.set_page_config(page_title="æ–°èæª¢ç´¢ç³»çµ±", page_icon="ğŸ“°")
st.title("ğŸ“° æ–°èæª¢ç´¢ç³»çµ±")
st.caption(f"ä½¿ç”¨ {MODEL_NAME} æ¨¡å‹é€²è¡Œèªæ„æœç´¢")

# --- å¿«å–è³‡æº ---
# ä½¿ç”¨ Streamlit çš„å¿«å–åŠŸèƒ½ï¼Œé¿å…é‡è¤‡åŠ è¼‰æ¨¡å‹å’Œè³‡æ–™åº«ï¼ŒåŠ å¿«åæ‡‰é€Ÿåº¦
@st.cache_resource
def load_model():
    """åŠ è¼‰ä¸¦å¿«å–å¥å­è½‰æ›å™¨æ¨¡å‹"""
    try:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        return SentenceTransformer(MODEL_NAME, device=device)
    except Exception as e:
        st.error(f"åŠ è¼‰æ¨¡å‹å¤±æ•—: {e}")
        return None

@st.cache_resource
def get_collection():
    """é€£æ¥ä¸¦å¿«å– ChromaDB é›†åˆ"""
    try:
        if not os.path.exists(DB_STORAGE_PATH):
            return None # è³‡æ–™åº«ä¸å­˜åœ¨
        client = chromadb.PersistentClient(path=DB_STORAGE_PATH)
        return client.get_collection(name=COLLECTION_NAME)
    except Exception as e:
        st.error(f"é€£æ¥è³‡æ–™åº«å¤±æ•—: {e}")
        return None

# --- ä¸»æ‡‰ç”¨ç¨‹å¼é‚è¼¯ ---
model = load_model()
collection = get_collection()

if model is None or collection is None:
    st.error("ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œç„¡æ³•æä¾›æœå‹™ã€‚")
    if not os.path.exists(DB_STORAGE_PATH):
        st.warning(f"æ‰¾ä¸åˆ°å‘é‡è³‡æ–™åº« ({DB_STORAGE_PATH})ã€‚è«‹å…ˆåŸ·è¡Œ `ingest_data.py` ä¾†å»ºç«‹è³‡æ–™åº«ã€‚")
else:
    # --- ä½¿ç”¨è€…è¼¸å…¥ ---
    query = st.text_input("è«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„é—œéµå­—æˆ–å¥å­ï¼š", placeholder="ä¾‹å¦‚ï¼šç¾åœ‹è¨­å» é€²åº¦")

    if query:
        # --- åŸ·è¡Œæª¢ç´¢ ---
        with st.spinner("æ­£åœ¨é€²è¡Œèªæ„æœç´¢..."):
            try:
                # 1. å°‡æŸ¥è©¢æ–‡å­—è½‰æ›ç‚ºå‘é‡ï¼ˆå¿…é ˆ normalizeï¼ï¼‰
                query_embedding = model.encode(
                    query,
                    normalize_embeddings=True
                ).tolist()

                # 2. åœ¨ ChromaDB ä¸­æŸ¥è©¢å€™é¸è³‡æ–™ï¼ˆç²å–è¼ƒå¤šçµæœä»¥ä¾¿ç¯©é¸ï¼‰
                # å…ˆç²å–è¼ƒå¤šçš„çµæœï¼Œä¹‹å¾Œæ ¹æ“šè·é›¢é–¾å€¼ç¯©é¸
                max_candidates = 30
                total_count = collection.count()
                n_results = min(max_candidates, total_count) if total_count > 0 else 1

                results = collection.query(
                    query_embeddings=[query_embedding],
                    n_results=n_results
                )

                # 3. æ ¹æ“šè·é›¢é–¾å€¼ç¯©é¸çµæœ
                DISTANCE_THRESHOLD = 1.3  # è·é›¢é–¾å€¼
                MAX_RESULTS = 10  # æœ€å¤šé¡¯ç¤ºçš„çµæœæ•¸é‡

                all_documents = results.get('documents', [[]])[0]
                all_distances = results.get('distances', [[]])[0]
                all_metadatas = results.get('metadatas', [[]])[0]

                # ç¯©é¸è·é›¢å°æ–¼é–¾å€¼çš„çµæœ
                filtered_results = [
                    (doc, dist, meta)
                    for doc, dist, meta in zip(all_documents, all_distances, all_metadatas)
                    if dist < DISTANCE_THRESHOLD
                ]

                # å¦‚æœçµæœè¶…é MAX_RESULTSï¼Œåªå–å‰ MAX_RESULTS ç­†
                filtered_results = filtered_results[:MAX_RESULTS]

                # 4. é¡¯ç¤ºçµæœ
                st.subheader(f"æª¢ç´¢çµæœï¼ˆè·é›¢ < {DISTANCE_THRESHOLD}ï¼‰ï¼š")

                if not filtered_results:
                    st.info(f"æ‰¾ä¸åˆ°è·é›¢å°æ–¼ {DISTANCE_THRESHOLD} çš„ç›¸é—œè³‡æ–™ã€‚è«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")
                else:
                    st.success(f"æ‰¾åˆ° {len(filtered_results)} ç­†ç›¸é—œçµæœ")
                    for i, (doc, dist, metadata) in enumerate(filtered_results):
                        # å°æ–¼ normalized vectorsï¼ŒL2 è·é›¢è½‰æ›ç‚ºé¤˜å¼¦ç›¸ä¼¼åº¦
                        # cosine_similarity = 1 - (L2_distance^2 / 2)
                        similarity = 1 - (dist ** 2 / 2)

                        st.markdown(f"### çµæœ {i+1}")

                        # é¡¯ç¤ºæ¨™é¡Œï¼ˆå¾ metadata å–å¾—ï¼‰
                        subject = metadata.get('subject', 'ç„¡æ¨™é¡Œ')
                        st.markdown(f"**ğŸ“° {subject}**")

                        # é¡¯ç¤ºæ—¥æœŸå’Œé¡å‹
                        news_date = metadata.get('news_date', 'æœªçŸ¥æ—¥æœŸ')
                        news_type = metadata.get('news_type', 'æœªçŸ¥é¡å‹')
                        st.markdown(f"ğŸ—“ï¸ **æ—¥æœŸ**: {news_date} | ğŸ·ï¸ **é¡å‹**: {news_type}")

                        # é¡¯ç¤ºç›¸ä¼¼åº¦
                        st.markdown(f"ğŸ“Š **ç›¸ä¼¼åº¦**: {similarity:.4f} (è·é›¢: {dist:.4f})")

                        # é¡¯ç¤ºå®Œæ•´å…§å®¹
                        with st.expander("æŸ¥çœ‹å®Œæ•´å…§å®¹", expanded=True):
                            st.markdown(doc)

                        st.divider()

            except Exception as e:
                st.error(f"æª¢ç´¢éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- é è…³ ---
st.markdown("---")
st.markdown("é€™æ˜¯ä¸€å€‹ä½¿ç”¨ Streamlitã€ChromaDB å’Œ Sentence Transformers å»ºç«‹çš„èªæ„æœç´¢æ‡‰ç”¨ç¨‹å¼ã€‚")
